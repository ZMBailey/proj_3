{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librosa: Music in Python\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as ms\n",
    "ms.use('seaborn-muted')\n",
    "%matplotlib inline\n",
    "\n",
    "import IPython.display\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Songs\n",
    "\n",
    "Librosa has a simple function to import an audio file, using `librosa.load()` to read most audio filetypes.\n",
    "This converts the audio file into a tuple containing 2 items: a timeseries representing the audio, and the sample rate. The sample rate is also an optional perameter for `load` with a default of 22050, measured in Hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Kaspar's version of loading songs\n",
    "import glob\n",
    "\n",
    "songs = []\n",
    "paths = glob.glob('songs/*.m4a')   # todo: addapt for other audio suffixes if needed\n",
    "paths += glob.glob('songs/*.mp3')\n",
    "\n",
    "for path in paths[:3]:\n",
    "    songname = path.rsplit('/', 1)[1][:-4]\n",
    "    audio, sr = librosa.load(path, res_type='kaiser_fast')\n",
    "    songs.append((audio, sr, songname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have an audio file represented as a timeseries, ubt what can we do with that? We could plot it like we would normally do with a timeseries, so let's see what that looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec = librosa.audio.time_to_samples(120)\n",
    "plt.plot(y[:sec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(songs[0][0])\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that's not very informative. So let's see what other information we can extrapolate from this data using librosa.\n",
    "\n",
    "### Mel Power Spectrograms\n",
    "\n",
    "The first thing we can do is convert our audio into the Mel scale. The Mel scale is a scale of pitches judged by listeners to be equal to each other. What this means is that we can create a mel spectrogram, which will show us pitch frequencey and decibel level in one image.\n",
    "\n",
    "Here we have spectrograms of songs by The Clash, Adele, and Heart. The y axis is in Hz, which means higher on the y axis is higher pitch. The colors tell us about dB level, where lighter colors indicate higher volume, and darker colors indicate lower volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []\n",
    "\n",
    "for i,song in enumerate(songs[:3]):\n",
    "    y,sr,title = song\n",
    "    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    logs.append(log_S)\n",
    "    \n",
    "    ls = log_S[:,:6000]\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "\n",
    "    # Display the spectrogram on a mel scale\n",
    "    # sample rate and hop length parameters are used to render the time axis\n",
    "    librosa.display.specshow(log_S, sr=sr, hop_length=512 ,x_axis='time', y_axis='mel')\n",
    "\n",
    "    plt.title(\"mel power spectrogram of \" + title)\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have zoomed in on 10 second segments of each song, to get a better look at the variations going on. Now we can better see how Rudie Can't Fail hits high notes at regular intervals, but only for brief moments. Rolling in the Deep starts out quieter and with lower pitches, and What About Love has a dip where the high notes fade for about 5 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = []\n",
    "start = [0, 0, 40]\n",
    "stop = [10, 10, 50]\n",
    "\n",
    "for i, song in enumerate(songs[:3]):\n",
    "    y, sr, title = song\n",
    "    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "    S = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "    # Convert to log scale (dB). We'll use the peak power (max) as reference.\n",
    "    log_S = librosa.power_to_db(S, ref=np.max)\n",
    "    logs.append(log_S)\n",
    "    \n",
    "    ls = log_S[:,3500:4000]\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    librosa.display.specshow(log_S, sr=sr, hop_length=512 ,x_axis='time', y_axis='mel')\n",
    "    plt.title(\"mel power spectrogram of \" + title)\n",
    "    plt.xlim((start[i],stop[i]))\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPython.display.Audio(data=y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Audio\n",
    "\n",
    "For this next part, We're going to split the audio into Harmonics and Percussive Tracks, which normally overlap to form the complete spectrograph. Then we can display them seperately, to disect our tracks a little futher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonics = []\n",
    "percussives = []\n",
    "\n",
    "for song in songs[:3]:\n",
    "    h, p = librosa.effects.hpss(song[0])\n",
    "    harmonics.append(h)\n",
    "    percussives.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,song in enumerate(songs[:3]):\n",
    "    y, sr, title = song\n",
    "    y_harmonic = harmonics[i]\n",
    "    y_percussive = percussives[i]\n",
    "    # Let's make and display a mel-scaled power (energy-squared) spectrogram\n",
    "    S_harmonic   = librosa.feature.melspectrogram(y_harmonic, sr=sr)\n",
    "    S_percussive = librosa.feature.melspectrogram(y_percussive, sr=sr)\n",
    "\n",
    "    # Convert to log scale (dB). We'll use the peak power as reference.\n",
    "    log_Sh = librosa.power_to_db(S_harmonic, ref=np.max)\n",
    "    log_Sp = librosa.power_to_db(S_percussive, ref=np.max)\n",
    "    lh = log_Sh[:,:6000]\n",
    "    lp = log_Sp[:,:6000]\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.subplot(2,1,1)\n",
    "    librosa.display.specshow(lh, sr=sr, y_axis='mel')\n",
    "    plt.title('mel power spectrogram (Harmonic) - ' + title)\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.subplot(2,1,2)\n",
    "    librosa.display.specshow(lp, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.title('mel power spectrogram (Percussive) - ' + title)\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    IPython.display.display(IPython.display.Audio(data=y, rate=sr))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitches and Keys\n",
    "\n",
    "With the harmonic and percussive tracks we can display a Chromograph, which is like a heatmap that shows the key and intensity of notes being played over time. Louder notes are displayed as lighter, and quieter is displayed as darker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, song in enumerate(songs[:3]):\n",
    "    y, sr, title = song\n",
    "    y_harmonic = harmonics[i]\n",
    "    y_percussive = percussives[i]\n",
    "    C = librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "\n",
    "    C_new = C[:,:6000]\n",
    "    # Display the chromagram: the energy in each chromatic pitch class as a function of time\n",
    "    # To make sure that the colors span the full range of chroma values, set vmin and vmax\n",
    "    plt.figure(figsize=(12,4))\n",
    "    librosa.display.specshow(C_new, sr=sr, x_axis='time', y_axis='chroma', vmin=0, vmax=1)\n",
    "\n",
    "    plt.title('Chromagram of ' + title)\n",
    "    plt.colorbar()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    IPython.display.display(IPython.display.Audio(data=y, rate=sr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at trends in these chromographs we can begin to have an idea of major keys for these songs. \n",
    "\n",
    "\n",
    "### Beats Per Minute\n",
    "\n",
    "Another thing we can look at is tempo and beats. By using `librosa.beat.tempo` we can extract the overall tempo for a song in beats per minute(bpm), but we can also use `librosa.beat.beat_track` to return the tempo and a numpy array containing the numbers of each beat. One thing we can do with this is to plot the spectrogram of the audio, but this time with the beats overlaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, song in enumerate(songs[:3]):\n",
    "    y, sr, title = songs[i]    \n",
    "    tempo, beats = librosa.beat.beat_track(y=percussives[i], sr=sr)\n",
    "    # Let's re-draw the spectrogram, but this time, overlay the detected beats\n",
    "    plt.figure(figsize=(12,4))\n",
    "    librosa.display.specshow(logs[i], sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.vlines(librosa.frames_to_time(beats, sr=sr),\n",
    "                   1, sr * 0.25,\n",
    "                   colors='white', linestyles='-', linewidth=2, alpha=0.5)\n",
    "    plt.xlim((0,30))\n",
    "    #plt.axis('tight')\n",
    "    plt.colorbar(format='%+02.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librosa.frames_to_time(beats)\n",
    "type(beats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = []\n",
    "paths = glob.glob('songs/*.mp3')   # todo: addapt for other audio suffixes if needed\n",
    "paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = paths[0]\n",
    "audio, sr = librosa.load(path, res_type='kaiser_fast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, p = librosa.effects.hpss(audio)\n",
    "IPython.display.display(IPython.display.Audio(data=h, rate=sr))\n",
    "IPython.display.display(IPython.display.Audio(data=p, rate=sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
